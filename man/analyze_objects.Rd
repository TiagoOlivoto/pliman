% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/analyze_objects.R
\name{analyze_objects}
\alias{analyze_objects}
\alias{plot.anal_obj}
\alias{analyze_objects_iter}
\title{Analyzes objects in an image}
\usage{
analyze_objects(
  img,
  foreground = NULL,
  background = NULL,
  reference = NULL,
  reference_area = NULL,
  pattern = NULL,
  parallel = FALSE,
  workers = NULL,
  watershed = TRUE,
  resize = FALSE,
  trim = FALSE,
  fill_hull = FALSE,
  filter = FALSE,
  invert = FALSE,
  object_size = "medium",
  index = "NB",
  my_index = NULL,
  object_index = NULL,
  threshold = "Otsu",
  tolerance = NULL,
  extension = NULL,
  lower_size = NULL,
  upper_size = NULL,
  topn_lower = NULL,
  topn_upper = NULL,
  lower_eccent = NULL,
  upper_eccent = NULL,
  lower_circ = NULL,
  upper_circ = NULL,
  randomize = TRUE,
  nrows = 2000,
  show_image = TRUE,
  show_original = TRUE,
  show_chull = FALSE,
  show_contour = TRUE,
  contour_col = "red",
  contour_size = 1,
  show_background = TRUE,
  show_segmentation = FALSE,
  col_foreground = NULL,
  col_background = NULL,
  marker = FALSE,
  marker_col = NULL,
  marker_size = NULL,
  save_image = FALSE,
  prefix = "proc_",
  dir_original = NULL,
  dir_processed = NULL,
  verbose = TRUE
)

\method{plot}{anal_obj}(
  x,
  which = "measure",
  measure = "area",
  type = "density",
  facet = FALSE,
  ...
)

analyze_objects_iter(pattern, known_area, verbose = TRUE, ...)
}
\arguments{
\item{img}{The image to be analyzed.}

\item{foreground}{A color palette of the foreground (optional).}

\item{background}{A color palette of the background (optional).}

\item{reference}{A color palette for a reference object (optional). This is
useful to adjust measures when images are not obtained with standard
resolution (e.g., field images). See more in the details section.}

\item{reference_area}{The known area of the reference objects. The measures
of all the objects in the image will be corrected using the same unit of
the area informed here.}

\item{pattern}{A pattern of file name used to identify images to be imported.
For example, if \code{pattern = "im"} all images in the current working
directory that the name matches the pattern (e.g., img1.-, image1.-, im2.-)
will be imported as a list. Providing any number as pattern (e.g., \code{pattern = "1"}) will select images that are named as 1.-, 2.-, and so on. An error
will be returned if the pattern matches any file that is not supported
(e.g., img1.pdf).}

\item{parallel}{If \code{TRUE} processes the images asynchronously (in parallel)
in separate R sessions running in the background on the same machine. It
may speed up the processing time, especially when \code{pattern} is used is
informed. When \code{object_index} is informed, multiple sections will be used
to extract the RGB values for each object in the image. This may
significantly speed up processing time when an image has lots of objects
(say >1000).}

\item{workers}{A positive numeric scalar or a function specifying the number
of parallel processes that can be active at the same time. By default, the
number of sections is set up to 50\% of available cores.}

\item{watershed}{If \code{TRUE} (default) performs watershed-based object
detection. This will detect objects even when they are touching one other.
If \code{FALSE}, all pixels for each connected set of foreground pixels are set
to a unique object. This is faster but is not able to segment touching
objects.}

\item{resize}{Resize the image before processing? Defaults to \code{FALSE}. Use a
numeric value of range 0-100 (proportion of the size of the original
image).}

\item{trim}{Number of pixels removed from edges in the analysis. The edges of
images are often shaded, which can affect image analysis. The edges of
images can be removed by specifying the number of pixels. Defaults to
\code{FALSE} (no trimmed edges).}

\item{fill_hull}{Fill holes in the binary image? Defaults to \code{FALSE}. This is
useful to fill holes in objects that have portions with a color similar to
the background. IMPORTANT: Objects touching each other can be combined into
one single object, which may underestimate the number of objects in an
image.}

\item{filter}{Performs median filtering after image processing? defaults to
\code{FALSE}. See more at \code{\link[=image_filter]{image_filter()}}.}

\item{invert}{Inverts the binary image, if desired. This is useful to process
images with black background. Defaults to \code{FALSE}.}

\item{object_size}{The size of the object. Used to automatically set up
\code{tolerance} and \code{extension} parameters. One of the following. \code{"small"}
(e.g, wheat grains), \code{"medium"} (e.g, soybean grains), \code{"large"}(e.g,
peanut grains), and \code{"elarge"} (e.g, soybean pods)`.}

\item{index, my_index}{A character value specifying the target mode for
conversion to binary image when \code{foreground} and \code{background} are not
declared. Defaults to \code{"NB"} (normalized blue). See \code{\link[=image_index]{image_index()}} for
more details.}

\item{object_index}{Defaults to \code{FALSE}. If an index is informed, the average
value for each object is returned. It can be the R, G, and B values or any
operation involving them, e.g., \code{object_index = "R/B"}. In this case, it
will return for each object in the image, the average value of the R/B
ratio. Use \code{\link[=pliman_indexes_eq]{pliman_indexes_eq()}} to see the equations of available indexes.}

\item{threshold}{By default (\code{threshold = "Otsu"}), a threshold value based
on Otsu's method is used to reduce the grayscale image to a binary image.
If a numeric value is informed, this value will be used as a threshold.
Inform any non-numeric value different than "Otsu" to iteratively chosen
the threshold based on a raster plot showing pixel intensity of the index.}

\item{tolerance}{The minimum height of the object in the units of image
intensity between its highest point (seed) and the point where it contacts
another object (checked for every contact pixel). If the height is smaller
than the tolerance, the object will be combined with one of its neighbors,
which is the highest.}

\item{extension}{Radius of the neighborhood in pixels for the detection of
neighboring objects. Higher value smooths out small objects.}

\item{lower_size, upper_size}{Lower and upper limits for size for the image
analysis. Plant images often contain dirt and dust. To prevent dust from
affecting the image analysis, objects with lesser than 10\% of the mean of
all objects are removed. Upper limit is set to \code{NULL}, i.e., no upper
limit used. One can set a known area or use \code{lower_limit = 0} to select all
objects (not advised). Objects that matches the size of a given range of
sizes can be selected by setting up the two arguments. For example, if
\code{lower_size = 120} and \code{upper_size = 140}, objects with size greater than
or equal 120 and less than or equal 140 will be considered.}

\item{topn_lower, topn_upper}{Select the top \code{n} objects based on its area.
\code{topn_lower} selects the \code{n} elements with the smallest area whereas
\code{topn_upper} selects the \code{n} objects with the largest area.}

\item{lower_eccent, upper_eccent, lower_circ, upper_circ}{Lower and upper limit
for object eccentricity/circularity for the image analysis. Users may use
these arguments to remove objects such as square papers for scale (low
eccentricity) or cut petioles (high eccentricity) from the images. Defaults
to \code{NULL} (i.e., no lower and upper limits).}

\item{randomize}{Randomize the lines before training the model?}

\item{nrows}{The number of lines to be used in training step. Defaults to
2000.}

\item{show_image}{Show image after processing?}

\item{show_original}{Show the count objects in the original image?}

\item{show_chull}{Show the convex hull around the objects? Defaults to
\code{FALSE}.}

\item{show_contour}{Show a contour line around the objects? Defaults
to \code{TRUE}.}

\item{contour_col, contour_size}{The color and size for the contour line
around objects. Defaults to \code{contour_col = "red"} and \code{contour_size = 1}.}

\item{show_background}{Show the background? Defaults to \code{TRUE}. A white
background is shown by default when \code{show_original = FALSE}.}

\item{show_segmentation}{Shows the object segmentation colored with random
permutations. Defaults to \code{FALSE}.}

\item{col_foreground, col_background}{Foreground and background color after
image processing. Defaults to \code{NULL}, in which \code{"black"}, and \code{"white"} are
used, respectively.}

\item{marker, marker_col, marker_size}{The type, color and size of the object
marker. Defaults to \code{NULL}, which plots the object id. Use \code{marker = "point"} to show a point in each object or \code{marker = FALSE} to omit object
marker.}

\item{save_image}{Save the image after processing? The image is saved in the
current working directory named as \verb{proc_*} where \code{*} is the image name
given in \code{img}.}

\item{prefix}{The prefix to be included in the processed images. Defaults to
\code{"proc_"}.}

\item{dir_original, dir_processed}{The directory containing the original and
processed images. Defaults to \code{NULL}. In this case, the function will
search for the image \code{img} in the current working directory. After
processing, when \code{save_image = TRUE}, the processed image will be also
saved in such a directory. It can be either a full path, e.g.,
\code{"C:/Desktop/imgs"}, or a subfolder within the current working directory,
e.g., \code{"/imgs"}.}

\item{verbose}{If \code{TRUE} (default) a summary is shown in the console.}

\item{x}{An object of class \code{anal_obj}.}

\item{which}{Which to plot. Either 'measure' (object measures) or 'index'
(object index). Defaults to \code{"measure"}.}

\item{measure}{The measure to plot. Defaults to \code{"area"}.}

\item{type}{The type of plot. Either \code{"hist"} or \code{"density"}. Partial matches
are recognized.}

\item{facet}{Create a facet plot for each object when \code{which = "index"} is
used?. Defaults to \code{FALSE}.}

\item{...}{Depends on the function:
\itemize{
\item For \code{\link[=analyze_objects_iter]{analyze_objects_iter()}}, further arguments passed on to
\code{\link[=analyze_objects]{analyze_objects()}}.
\item For \code{\link[=plot.anal_obj]{plot.anal_obj()}}, further argument passed on to \code{\link[lattice:histogram]{lattice::histogram()}}
or \code{\link[lattice:histogram]{lattice::densityplot()}}
}}

\item{known_area}{The known area of the template object.}
}
\value{
\code{analyze_objects()} returns a list with the following objects:
\itemize{
\item \code{results} A data frame with the following variables for each object in the
image:
\itemize{
\item \code{id}:  object identification.
\item \code{x},\code{y}:  x and y coordinates for the center of mass of the object.
\item \code{area}:  area of the object (in pixels).
\item \code{area_ch}:  the area of the convex hull around object (in pixels).
\item \code{perimeter}: perimeter (in pixels).
\item \code{radius_min}, \code{radius_mean}, and \code{radius_max}: The minimum, mean, and
maximum radius (in pixels), respectively.
\item \code{radius_sd}: standard deviation of the mean radius (in pixels).
\item \code{diam_min}, \code{diam_mean}, and \code{diam_max}: The minimum, mean, and
maximum diameter (in pixels), respectively.
\item \code{major_axis}, \code{minor_axis}: elliptical fit for major and minor axes (in
pixels).
\item \code{length}, \code{width} The length and width of objects (in pixels). These
measures are obtained as the range of x and y coordinates after aligning
each object with \code{poly_align()}.
\item \code{radius_ratio}: radius ratio given by \code{radius_max / radius_min}.
\item \code{eccentricity}: elliptical eccentricity computed using the
ratio of the eigen values (inertia axes of coordinates).
\item \code{theta}: object angle (in radians).
\item \code{solidity}: object solidity given by \code{area / area_ch}.
\item \code{convexity}: The convexity of the object computed using the ratio
between the perimeter of the convex hull and the perimeter of the polygon.
\item \code{elongation}: The elongation of the object computed as \code{1 - width / length}.
\item \code{circularity}: The object circularity given by \code{perimeter ^ 2 / area}.
\item \code{circularity_haralick}: The Haralick's circularity (CH), computed as
\code{CH =  m/sd}, where \code{m} and \code{sd} are the mean and standard deviations
from each pixels of the perimeter to the centroid of the object.
\item \code{circularity_norm}: The normalized circularity (Cn), to be unity for a
circle. This measure is computed as `Cn = perimeter ^ 2 / 4\emph{pi}area`` and
is invariant under translation, rotation, scaling transformations, and
dimensionless.
}
\item \code{statistics}: A data frame with the summary statistics for the area of the
objects.
\item \code{count}: If \code{pattern} is used, shows the number of objects in each image.
\item \code{object_rgb}: If \code{object_index} is used, returns the R, G, and B values
for each pixel of each object.
\item \code{object_index}: If \code{object_index} is used, returns the index computed for
each object.
\item \code{analyze_objects_iter()} returns a data.frame containing the features
described in the \code{results} object of \code{\link[=analyze_objects]{analyze_objects()}}.
\item \code{plot.anal_obj()} returns a \code{trellis} object containing the distribution
of the pixels, optionally  for each object when \code{facet = TRUE} is used.
}
}
\description{
\itemize{
\item \code{\link[=analyze_objects]{analyze_objects()}} provides tools for counting and extracting object
features (e.g., area, perimeter, radius, pixel intensity) in an image. See
more at \strong{Details} section.
\item \code{\link[=analyze_objects_iter]{analyze_objects_iter()}} provides an iterative section to measure object
features using an object with a known area.
\item \code{\link[=plot.anal_obj]{plot.anal_obj()}} Produces an histogram for the R, G, and B values when
argument \code{object_index} is used in the function \code{\link[=analyze_objects]{analyze_objects()}}.
}
}
\details{
A binary image is first generated to segment the foreground and background.
The argument \code{index} is useful to choose a proper index to segment the image
(see \code{\link[=image_binary]{image_binary()}} for more details). Then, the number of objects in the
foreground is counted. By setting up arguments such as \code{lower_size},
\code{upper_size} it is possible to set a threshold for lower and upper sizes of
the objects, respectively. The argument \code{object_size} can be used to set up
pre-defined values of \code{tolerance} and \code{extension} depending on the image
resolution. This will influence the watershed-based object segmentation. Users
can also tune-up \code{tolerance} and \code{extension} explicitly to a better precision
of watershed segmentation.

If \code{watershed = FALSE} is used, all pixels for each connected set of
foreground pixels in \code{img} are set to a unique object. This is faster
(specially for a large number of objects) but is not able to segment touching
objects.

If color palettes are provided, a general linear model (binomial family)
fitted to the RGB values is used to segment fore- and background. If a color
palette for a \code{reference} object with a known area (\code{reference_area}) is
informed. The measures of the objects in the image will be corrected
considering the unit of measure informed in \code{reference_area}. Sample palettes
can be produced with \code{\link[=image_palette]{image_palette()}}.

By using \code{pattern} it is possible to process several images with common
pattern names that are stored in the current working directory or in the
subdirectory informed in \code{dir_original}'. To speed up the computation time,
one can set \code{parallel = TRUE}.

\code{\link[=analyze_objects_iter]{analyze_objects_iter()}} can be used to process several images using an
object with a known area as a template. In this case, all the images in the
current working directory that matches the \code{pattern} will be processed. For
each image, the function will compute the features for the objects and show
the identification (id) of each object. The user only needs to inform which
is the id of the known object. Then, given the \code{known_area}, all the measures
will be adjusted. In the end, a data.frame with the adjusted measures will be
returned. This is useful when the images are taken at different heights. In
such cases, the image resolution cannot be conserved. Consequently, the
measures cannot be adjusted using the argument \code{dpi} from \code{\link[=get_measures]{get_measures()}},
since each image will have a different resolution. NOTE: This will only work
in an interactive section.
}
\examples{
\donttest{
library(pliman)
img <- image_pliman("soybean_touch.jpg")
obj <- analyze_objects(img)
obj$statistics

# Enumerate the objects in the original image
# Return the top-5 grains with the largest area

top <-
 analyze_objects(img,
                 marker = "id",
                 topn_upper = 5)
top$results
}

\donttest{
library(pliman)

img <- image_pliman("soy_green.jpg")
# Segment the foreground (grains) using the normalized blue index (NB, default)
# Shows the average value of the blue index in each object

rgb <-
   analyze_objects(img,
                   marker = "id",
                   object_index = "B")
# density of area
plot(rgb)

# histogram of perimeter
plot(rgb, measure = "perimeter", type = "histogram") # or 'hist'

# density of the blue (B) index
plot(rgb, which = "index")
}
}
\references{
Gupta, S., Rosenthal, D. M., Stinchcombe, J. R., & Baucom, R. S. (2020). The
remarkable morphological diversity of leaf shape in sweet potato (Ipomoea
batatas): the influence of genetics, environment, and G×E. New Phytologist,
225(5), 2183–2195. \doi{10.1111/NPH.16286}

Lee, Y., & Lim, W. (2017). Shoelace Formula: Connecting the Area of a Polygon
and the Vector Cross Product. The Mathematics Teacher, 110(8), 631–636.
\doi{10.5951/mathteacher.110.8.0631}

Montero, R. S., Bribiesca, E., Santiago, R., & Bribiesca, E. (2009). State
of the Art of Compactness and Circularity Measures. International
Mathematical Forum, 4(27), 1305–1335.

Chen, C.H., and P.S.P. Wang. 2005. Handbook of Pattern Recognition and
Computer Vision. 3rd ed. World Scientific.
}
\author{
Tiago Olivoto \email{tiagoolivoto@gmail.com}
}
