---
title: "Analyzing objects in an image"
author: "Tiago Olivoto"
date: "`r Sys.Date()`"
always_allow_html: yes
output:
  html_document:
    df_print: paged
fig_caption: yes
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  rmarkdown.html_vignette.check_title = FALSE,
  fig.width = 10
)
```


# Getting started

The function `analyze_objects()` can be used to count objects in an image. Let us start with a simple example with the image `object_300dpi.png` available on the [GitHub page](https://github.com/TiagoOlivoto/pliman/tree/master/image_examples). To facilitate the image importation from this folder, a helper function `image_pliman()` is used.

```{r}
library(pliman)
img <- image_pliman("objects_300dpi.jpg", plot = TRUE)
```

The above image was produced with Microsoft PowerPoint. It has a known resolution of 300 dpi (dots per inch) and shows four objects

-   Larger square: 10 x 10 cm (100 cm^2^)
-   Smaller square: 5 x 5 cm (25 cm^2^)
-   Rectangle: 4 x 2 cm (8 cm^2^)
-   Circle: 3 cm in diameter (\~7.08 cm^2^)

To count the objects in the image we use `analyze_objects()` and inform the image object (the only mandatory argument). First, we use `image_binary()` to see the most suitable index to segment the objects from the background. By default, the R, G, B (first row) and their normalized values (second row) are used.

```{r fig.width=10, fig.height=5}
image_binary(img)
```

# Analyzing objects
```{r, fig.width=10, fig.height=5}
img_res <- 
  analyze_objects(img,
                  marker = "id",
                  index = "B") # use blue index to segment

```

# Adjusting object measures

The results were stored in `img_res`. Since there is no scale declared in the above example, we have no idea about the actual area of the objects in cm^2^, only in pixels. In this case, we use `get_measures()` to adjust the measures from pixels to metric units.

There are two main ways of adjusting the object measures (from pixels to cm, for example). The first one is to declare the known area, perimeter, or radius of a given object. The measure for the other objects will be then computed by a simple rule of three. The second one is by declaring a known image resolution in dpi (dots per inch). In this case, the perimeter, area, and radius will be adjusted by the informed dpi. 

## Declaring a known value 
Since we have known the area of the larger square (object 1), let us adjust the area of the other objects in the image using that.

```{r}
get_measures(img_res,
             id = 1,
             area ~ 100) |> 
  str()
```

The same can be used to adjust the measures based on the perimeter or radius. Let us adjust the perimeter of objects by the perimeter of object 2 (20 cm).

```{r}
get_measures(img_res,
             id = 2,
             perimeter ~ 20) |> 
  str()
```

## Declaring the image resolution

If the image resolution is known, all the measures will be adjusted according to this resolution. Let us to see a numerical example with `pixels_to_cm()`. This function converts the number of pixels ($px$) to cm, considering the image resolution in $dpi$, as follows: $cm = px \times (2.54/dpi)$. Since we know the number of pixels of the larger square, its perimeter in cm is given by

```{r}
# number of pixels for the highest square perimeter
ls_px <- img_res$results$perimeter[1]
pixels_to_cm(px = ls_px, dpi = 300)

```
The perimeter of object 1 adjusted by the image resolution is very close to the true (40 cm). Bellow, the values of all measures are adjusted by declaring the `dpi` argument in `get_measures()`.

```{r}
get_measures(img_res, dpi = 300) |> str()
```


# Counting crop grains 

Here, we will count the grains in the image `soybean_touch.jpg`. This image has a cyan background and contains 30 soybean grains that touch with each other. Two segmentation strategies are used. The first one is by using is image segmentation based on color indexes. 

```{r,fig.width=10, fig.height=5}
soy <-        image_pliman("soybean_touch.jpg")
grain <-      image_pliman("soybean_grain.jpg")
background <- image_pliman("la_back.jpg")
image_combine(soy, grain, background, ncol = 3)
```

The function `analyze_objects()` segment the image using as default the normalized blue index, as follows $NB = (B/(R+G+B))$, where $R$, $G$, and $B$ are the red, green, and blue bands. Objects are count and the segmented objects are colored with random permutations.

```{r,fig.width=10, fig.height=5}
count2 <- 
  analyze_objects(soy,
                  index = "NB") # default

```

Users can set `show_contour = FALSE` to remove the contour line and identify the objects (in this example the grains) by using the arguments `marker = "id"`. The color of the background can also be changed with `col_background`.

```{r,fig.width=10, fig.height=5}
count <- 
  analyze_objects(soy,
                  show_contour = FALSE,
                  marker = "id",
                  show_segmentation = FALSE,
                  col_background = "white",
                  index = "NB") # default
```

```{r}
# Get the object measures
measures <- get_measures(count)
str(measures)
```

In the following example, we will select objects with an area above the average of all objects by using `lower_size = 2057.36`. Additionally, we will use the argument `show_original = FALSE` to show the results as colors (non-original image).

```{r,fig.width=10, fig.height=5}
analyze_objects(soy,
                marker = "id",
                show_original = FALSE,
                lower_size = 2057.36,
                index = "NB") # default
```

Users can also use the `topn_*` arguments to select the top `n` objects based on either smaller or largest areas. Let's see how to point out the 5 grains with the smallest area, showing the original grains in a blue background. We will also use the argument `index` to choose a personalized index to segment the image. Just for comparison, we will set up explicitly the normalized blue index by calling `index = "B/(R+G+B)"`.

```{r,fig.width=10, fig.height=5}
analyze_objects(soy,
                marker = "id",
                topn_lower = 5,
                col_background = "blue",
                index = "B/(R+G+B)") # default
```



# Using sample palettes

Sometimes it is difficult to choose an image index that segments the image efficiently (even using `index` ). In `pliman` users have an alternative image segmentation strategy that is using sample color palettes. In this case, users can say to `analyze_objects` which color palettes are to be used for background and foreground. A generalized linear model (binomial family) is then used to predict the value of each pixel (background or foreground). Let's see how the grains of the above image can be counted with this strategy.

```{r,fig.width=10, fig.height=5}
analyze_objects(img = soy,
                background = background,
                foreground = grain)
```


Provided that the images are stored in the current working directory (or subdirectory), users can count the objects with no need to first import the image into the R environment. In this case, image names need to be declared as characters. Assuming that soy, background, and grain are the images saved into the current working directory, the same result as above is obtained with

```{r eval=FALSE}
analyze_objects(img = "soy",
                background = "background",
                foreground = "grain")
```


# Leaf shape

The function `analyze_objects()` computes a range of object features that can be used to study leaf shape. As a motivating example, I will use the image `potato_leaves.png`, which was gathered from Gupta et al. (2020)^[Gupta, S., Rosenthal, D. M., Stinchcombe, J. R., & Baucom, R. S. (2020). The remarkable morphological diversity of leaf shape in sweet potato (*Ipomoea batatas*): the influence of genetics, environment, and G×E. *New Phytologist*, 225(5), 2183–2195. https://doi.org/10.1111/nph.16286]



```{r potato, fig.width=10}
potato <- image_pliman("potato_leaves.jpg", plot = TRUE)
pot_meas <-
  analyze_objects(potato,
                  watershed = FALSE,
                  marker = "id",
                  show_chull = TRUE) # shows the convex hull
str(pot_meas)
```

Three key measures (in pixel units) are:

1. `area` the area of the object.
2. `area_ch` the area of the convex hull.
3. `perimeter` the perimeter of the object.

Using these measures, circularity and solidity are computed as shown in (Gupta et al, 2020).

$$ circularity = 4\pi(area / perimeter^2)$$


$$solidity = area / area\_ch$$

Circularity is influenced by serrations and lobing. Solidity is sensitive to leaves with deep lobes, or with a distinct petiole, and can be used to distinguish leaves lacking such structures. Unlike circularity, it is not very sensitive to serrations and minor lobings, since the convex hull remains largely unaffected.


## Object contour

Users can also obtain the object contour and convex hull as follows:

```{r cont, fig.width=10}
cont <-
  object_contour(potato,
                 watershed = FALSE,
                 plot = FALSE)
plot(potato)
plot_contour(cont, col = "red", lwd = 3)
```

## Convex hull
The function `object_contour()` returns a list with the coordinate points for each object contour that can be further used to obtain the convex hull with `conv_hull()`.

```{r conv, fig.width=10}
conv <- conv_hull(cont)
plot(potato)
plot_contour(conv, col = "red", lwd = 3)
```


## Area of the convex hull
Then, the area of the convex hull can be obtained with `poly_area()`.
```{r polyarea}
(area <- poly_area(conv))
```


## Leaves as base plot

```{r maskpoly, fig.width=8}
# create a data frame for contour and convex hull
df_cont <-
  do.call(rbind,
          lapply(seq_along(cont), function(i){
            transform(as.data.frame(cont[[i]]), object = names(cont[i]))
          }))

df_conv <-  
  do.call(rbind,
          lapply(seq_along(conv), function(i){
            transform(as.data.frame(conv[[i]]), object = names(conv[i]))
          }))


# plot the objects
palette(c("red","blue","green"))
with(df_cont,
     plot(V1, V2, 
          cex = 0.5,
          col = object,
          xlab = NA,
          ylab = NA,
          axes = F))
with(subset(df_conv, object == 1),
     polygon(V1, V2, 
             col = rgb(1, 0, 0, 0.2),
             border = NA))
with(subset(df_conv, object == 2),
     polygon(V1, V2, 
             col = rgb(0, 0, 1, 0.2),
             border = NA))
with(subset(df_conv, object == 3),
     polygon(V1, V2, 
             col = rgb(0, 1, 0, 0.2),
             border = NA))

```

Or do the same with `ggplot2`
```{r eval=FALSE}
library(ggplot2)
ggplot(df_cont, aes(V1, V2, group = object)) +
  geom_polygon(aes(fill = object)) +
  geom_polygon(data = df_conv,
               aes(V1, V2, fill = object),
               alpha = 0.3) +
  theme_void() +
  theme(legend.position = "bottom")
```


# Batch processing
In plant image analysis, frequently it is necessary to process more than one image. For example, in plant breeding, the number of grains per plant (e.g., wheat) is frequently used in the indirect selection of high-yielding plants. In `pliman`, batch processing can be done when the user declares the argument `pattern`.

The following example would be used to count the objects in the images with a pattern name `"trat"` (e.g., `"trat1"`, `"trat2"`, `"tratn"`) saved into the subfolder "`originals"` in the current working directory. The processed images will be saved into the subfolder `"processed"`. The object `list_res` will be a list with two objects (`results` and `statistics`) for each image.

To speed up the processing time, especially for a large number of images, the argument `parallel = TRUE` can be used. In this case, the images are processed asynchronously (in parallel) in separate `R` sessions running in the background on the same machine. The number of sections is set up to 50% of available cores. This number can be controlled explicitly with the argument `workers`.

```{r eval=FALSE}
list_res <- 
  analyze_objects(pattern = "trat", # matches the name pattern in 'originals' subfolder
                  dir_original = "originals",
                  dir_processed = "processed",
                  parallel = TRUE, # parallel processing
                  workers = 8, # 8 multiple sections
                  save_image = TRUE)
```


# <i class="fas fa-scroll"></i> A little bit more!

<!-- inicio font awesome -->
<script src="https://kit.fontawesome.com/1f72d6921a.js" crossorigin="anonymous"></script>

> At [this link](https://tiagoolivoto.github.io/paper_pliman/code.html) you will find more examples on how to use {pliman} to analyze plant images. Source code and images can be downloaded [here](https://github.com/TiagoOlivoto/paper_pliman/archive/refs/heads/master.zip). You can also find a talk (Portuguese language) about {pliman} [here](https://www.youtube.com/watch?v=ElvUVlPocgA). <i class="far fa-lightbulb"></i>Lights, <i class="fas fa-camera"></i>camera, {pliman}!
